{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6847931,"sourceType":"datasetVersion","datasetId":3936750},{"sourceId":6865136,"sourceType":"datasetVersion","datasetId":3945154},{"sourceId":6890527,"sourceType":"datasetVersion","datasetId":3942644},{"sourceId":6971638,"sourceType":"datasetVersion","datasetId":3961875},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":150784240,"sourceType":"kernelVersion"}],"dockerImageVersionId":30579,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* This is worth mentioning that the Public LB for this competition is highly overfitted since you can see the test set is so small. Even including a text preprocessing (which is a standard process) pipeline is decreasing the score on the LB. So I would like to advise all the people who are directly forking and making the submissions to not completely rely on these notebooks. Try making more robust models with text cleaning and preprocessing functions, better text encoders like Word2Vec, BERT and better models like LSTMs (Sequential) or GNNs (Graph-Based) so that you have a good score in the Private LB as well.\n","metadata":{}},{"cell_type":"markdown","source":"* The next few notebooks I'll publish will be having better models and text preprocessing pipelines. Just a heads up, I have made some submissions with a private notebook and the scores are not good, but we'll see that these notebooks will score higher on the Private LB.","metadata":{}},{"cell_type":"markdown","source":"Credits : https://www.kaggle.com/code/xiaocao123/ai-generated-text-detection-add-new-data/notebook?scriptVersionId=151231725","metadata":{}},{"cell_type":"markdown","source":"# Importing library","metadata":{}},{"cell_type":"code","source":"!pip install -q language-tool-python --no-index --find-links ../input/daigt-misc/\n!mkdir -p /root/.cache/language_tool_python/\n!cp -r /kaggle/input/daigt-misc/lang57/LanguageTool-5.7 /root/.cache/language_tool_python/LanguageTool-5.7","metadata":{"execution":{"iopub.status.busy":"2023-11-21T23:46:42.211088Z","iopub.execute_input":"2023-11-21T23:46:42.211445Z","iopub.status.idle":"2023-11-21T23:47:03.349796Z","shell.execute_reply.started":"2023-11-21T23:46:42.211416Z","shell.execute_reply":"2023-11-21T23:47:03.348798Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport language_tool_python\nfrom concurrent.futures import ProcessPoolExecutor\nseed = 202","metadata":{"execution":{"iopub.status.busy":"2023-11-21T23:46:34.450320Z","iopub.execute_input":"2023-11-21T23:46:34.450809Z","iopub.status.idle":"2023-11-21T23:46:37.243604Z","shell.execute_reply.started":"2023-11-21T23:46:34.450777Z","shell.execute_reply":"2023-11-21T23:46:37.242169Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlanguage_tool_python\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProcessPoolExecutor\n\u001b[1;32m     12\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m202\u001b[39m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'language_tool_python'"],"ename":"ModuleNotFoundError","evalue":"No module named 'language_tool_python'","output_type":"error"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-21T23:46:37.244596Z","iopub.status.idle":"2023-11-21T23:46:37.244904Z","shell.execute_reply.started":"2023-11-21T23:46:37.244762Z","shell.execute_reply":"2023-11-21T23:46:37.244777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=202):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T23:46:37.245704Z","iopub.status.idle":"2023-11-21T23:46:37.246056Z","shell.execute_reply.started":"2023-11-21T23:46:37.245853Z","shell.execute_reply":"2023-11-21T23:46:37.245872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Imports and Feature Engineering","metadata":{}},{"cell_type":"code","source":"tool = language_tool_python.LanguageTool('en-US')\ndef correct_sentence(sentence):\n    return tool.correct(sentence)\ndef correct_df(df):\n    with ProcessPoolExecutor() as executor:\n        df['text'] = list(executor.map(correct_sentence, df['text']))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:52:32.642740Z","iopub.execute_input":"2023-11-21T14:52:32.643116Z","iopub.status.idle":"2023-11-21T14:52:34.868243Z","shell.execute_reply.started":"2023-11-21T14:52:32.643086Z","shell.execute_reply":"2023-11-21T14:52:34.867264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def how_many_typos(text):    \n    return len(tool.check(text))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:52:35.714547Z","iopub.execute_input":"2023-11-21T14:52:35.714883Z","iopub.status.idle":"2023-11-21T14:52:35.720015Z","shell.execute_reply.started":"2023-11-21T14:52:35.714858Z","shell.execute_reply":"2023-11-21T14:52:35.719262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_persuade_df = train[train['source'] != 'persuade_corpus']\npersuade_df = train[train['source'] == 'persuade_corpus']\nsampled_persuade_df = persuade_df.sample(n=6000, random_state=42)\n# Testing idea from discussion with @nbroad about limited characters in human essays\nall_human = set(list(''.join(sampled_persuade_df.text.to_list())))\nother = set(list(''.join(not_persuade_df.text.to_list())))\nchars_to_remove = ''.join([x for x in other if x not in all_human])\nprint(chars_to_remove)\n\ntranslation_table = str.maketrans('', '', chars_to_remove)\ndef remove_chars(s):\n    return s.translate(translation_table)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:52:39.102508Z","iopub.execute_input":"2023-11-21T14:52:39.103322Z","iopub.status.idle":"2023-11-21T14:52:41.303382Z","shell.execute_reply.started":"2023-11-21T14:52:39.103225Z","shell.execute_reply":"2023-11-21T14:52:41.301928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train[train[\"label\"]==1].sample(8000)\ntrain = train[train.RDizzl3_seven == True].reset_index(drop=True)\ntrain = pd.concat([train,train_data])\ntrain['text'] = train['text'].str.replace('\\n', '')\ntrain['text'] = train['text'].apply(remove_chars)\n\ntest = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\ntest['text'] = test['text'].str.replace('\\n', '')\ntest['text'] = test['text'].apply(remove_chars)\ncorrect_df(test)\ndf = pd.concat([train['text'], test['text']], axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:52:45.008920Z","iopub.execute_input":"2023-11-21T14:52:45.009441Z","iopub.status.idle":"2023-11-21T14:52:53.961997Z","shell.execute_reply.started":"2023-11-21T14:52:45.009398Z","shell.execute_reply":"2023-11-21T14:52:53.960546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(3, 6),sublinear_tf=True)\nvectorizer = vectorizer.fit(test['text'])\nX = vectorizer.transform(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:53:02.367718Z","iopub.execute_input":"2023-11-21T14:53:02.368138Z","iopub.status.idle":"2023-11-21T14:53:33.560654Z","shell.execute_reply.started":"2023-11-21T14:53:02.368102Z","shell.execute_reply":"2023-11-21T14:53:33.559139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"lr=LogisticRegression()\nsgd_model = SGDClassifier(max_iter=5000, tol=1e-3, loss=\"modified_huber\")   \nsgd_model2 = SGDClassifier(max_iter=5000, tol=1e-3, loss=\"modified_huber\", class_weight=\"balanced\") \nsgd_model3 = SGDClassifier(max_iter=10000, tol=5e-4, loss=\"modified_huber\", early_stopping=True) ","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:54:15.916327Z","iopub.execute_input":"2023-11-21T14:54:15.916690Z","iopub.status.idle":"2023-11-21T14:54:15.923775Z","shell.execute_reply.started":"2023-11-21T14:54:15.916659Z","shell.execute_reply":"2023-11-21T14:54:15.922193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Voting Classifier","metadata":{}},{"cell_type":"code","source":"ensemble = VotingClassifier(estimators=[('sgd', sgd_model),('sgd2', sgd_model2),('sgd3', sgd_model3)],voting='soft')\nensemble.fit(X[:train.shape[0]], train.label)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:54:18.444528Z","iopub.execute_input":"2023-11-21T14:54:18.444895Z","iopub.status.idle":"2023-11-21T14:54:18.531248Z","shell.execute_reply.started":"2023-11-21T14:54:18.444865Z","shell.execute_reply":"2023-11-21T14:54:18.530326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_test = ensemble.predict_proba(X[train.shape[0]:])[:,1]","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:54:21.478760Z","iopub.execute_input":"2023-11-21T14:54:21.479188Z","iopub.status.idle":"2023-11-21T14:54:21.486124Z","shell.execute_reply.started":"2023-11-21T14:54:21.479153Z","shell.execute_reply":"2023-11-21T14:54:21.484980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_test","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:54:25.177922Z","iopub.execute_input":"2023-11-21T14:54:25.178374Z","iopub.status.idle":"2023-11-21T14:54:25.185097Z","shell.execute_reply.started":"2023-11-21T14:54:25.178341Z","shell.execute_reply":"2023-11-21T14:54:25.184154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"ntypos=test['text'].apply(lambda x: how_many_typos(x))\ntest['ntypos'] = -ntypos\ntest['generated'] = preds_test","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:54:28.016126Z","iopub.execute_input":"2023-11-21T14:54:28.016512Z","iopub.status.idle":"2023-11-21T14:54:28.293134Z","shell.execute_reply.started":"2023-11-21T14:54:28.016481Z","shell.execute_reply":"2023-11-21T14:54:28.292224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test[\"id\"],\n    'generated': test['generated']\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:54:31.321711Z","iopub.execute_input":"2023-11-21T14:54:31.322101Z","iopub.status.idle":"2023-11-21T14:54:31.333393Z","shell.execute_reply.started":"2023-11-21T14:54:31.322068Z","shell.execute_reply":"2023-11-21T14:54:31.331781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:54:48.926576Z","iopub.execute_input":"2023-11-21T14:54:48.926971Z","iopub.status.idle":"2023-11-21T14:54:48.934865Z","shell.execute_reply.started":"2023-11-21T14:54:48.926940Z","shell.execute_reply":"2023-11-21T14:54:48.933662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}